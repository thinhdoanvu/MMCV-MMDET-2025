_base_ = 'sparse_rcnn/sparse-rcnn_r50_fpn_1x_coco.py'  # ğŸ“¦ Backbone: ResNet-50 + FPN

# ğŸ“¦ Dataset & class info
dataset_type = 'CocoDataset'
data_root = 'data/coco/'

classes = ('aortic_valve',)

# ğŸ§  Model: Sparse R-CNN + sá»­a sá»‘ lá»›p
model = dict(
    roi_head=dict(
        _delete_=True,  # âš ï¸ XÃ³a roi_head gá»‘c Ä‘á»ƒ ghi Ä‘Ã¨ toÃ n bá»™
        type='SparseRoIHead',
        num_stages=6,
        stage_loss_weights=[1.0] * 6,
        proposal_feature_channel=256,
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]
        ),
        bbox_head=[
            dict(
                type='DIIHead',
                num_classes=len(classes),  # âš ï¸ ÄÃ¢y lÃ  chá»— báº¡n thay Ä‘á»•i
                loss_cls=dict(
                    type='FocalLoss',
                    use_sigmoid=True,
                    gamma=2.0,
                    alpha=0.25,
                    loss_weight=2.0
                ),
                loss_bbox=dict(type='L1Loss', loss_weight=5.0),
                loss_iou=dict(type='GIoULoss', loss_weight=2.0)
            )
        ] * 6
    )
)


# ğŸ“¦ Train/Test pipeline
backend_args = None

train_pipeline = [
    dict(type='LoadImageFromFile', backend_args=backend_args),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='Resize', scale=(640, 640), keep_ratio=True),
    dict(type='PackDetInputs')
]

test_pipeline = [
    dict(type='LoadImageFromFile', backend_args=backend_args),
    dict(type='Resize', scale=(640, 640), keep_ratio=True),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(
        type='PackDetInputs',
        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor')
    )
]

# ğŸ” Dataloaders
train_dataloader = dict(
    batch_size=4,
    num_workers=4,
    persistent_workers=False,
    dataset=dict(
        type=dataset_type,
        metainfo=dict(classes=classes),
        data_root=data_root,
        ann_file='annotations/instances_train2017.json',
        data_prefix=dict(img='images/'),
        pipeline=train_pipeline
    )
)

val_dataloader = dict(
    batch_size=4,
    num_workers=4,
    persistent_workers=False,
    dataset=dict(
        type=dataset_type,
        metainfo=dict(classes=classes),
        data_root=data_root,
        ann_file='annotations/instances_val2017.json',
        data_prefix=dict(img='images/'),
        pipeline=test_pipeline
    )
)

# ğŸ“Š Evaluation
val_evaluator = dict(
    type='CocoMetric',
    ann_file=data_root + 'annotations/instances_val2017.json',
    metric='bbox'
)

# ğŸ’¾ Checkpointing
default_hooks = dict(
    checkpoint=dict(
        type='CheckpointHook',
        save_best='coco/bbox_mAP',
        rule='greater'
    )
)

# ğŸ”§ Optimizer (Sparse R-CNN dÃ¹ng SGD máº·c Ä‘á»‹nh)
# Náº¿u muá»‘n dÃ¹ng AdamW nhÆ° DETR thÃ¬ cÃ³ thá»ƒ sá»­a láº¡i optimizer á»Ÿ Ä‘Ã¢y

# ğŸƒ Train config
train_cfg = dict(max_epochs=200, val_interval=1)